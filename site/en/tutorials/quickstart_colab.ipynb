{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QhPWE1lwZHH"
      },
      "source": [
        "# Gemini API Python quickstart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa7c47ae6451"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/quickstart_colab\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on Google AI</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/quickstart_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db29b8d4247e"
      },
      "source": [
        "This tutorial shows you how to get started with the Gemini API using the Python SDK."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNNg43Ymw54e"
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "You can run this tutorial in Google Colab, which doesn't require additional environment configuration.\n",
        "\n",
        "Alternatively, to complete this quickstart locally, see the Python guidance in [Get started with the Gemini API](https://ai.google.dev/tutorials/quickstart)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHkHARdb1ZID"
      },
      "source": [
        "## Install the SDK\n",
        "\n",
        "The Python SDK for the Gemini API is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J6Pd9SFJ1yVi"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeMCtmx9ykyx"
      },
      "source": [
        "## Set up your API key\n",
        "\n",
        "To use the Gemini API, you'll need an API key. If you don't already have one, create a key in Google AI Studio.\n",
        "\n",
        "<a class=\"button\" href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>\n",
        "\n",
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then pass the key to the SDK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HTiaTu6O1LRC"
      },
      "outputs": [],
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY=\"AIzaSyA5HtRnzGruiia-aKtMMLnBjJ0ovTh11nE\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZPYk29o2No0"
      },
      "source": [
        "## Initialize the Generative Model\n",
        "\n",
        "Before you can make any API calls, you need to initialize the Generative Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s-JqXcDe2hZ_"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXxypzJH4MUl"
      },
      "source": [
        "## Generate text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j51mcrLD4Y2W",
        "outputId": "590b9ee8-3c0f-4966-ae9e-cffcb29751ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the quaint town of Willow Creek, resided a peculiar backpack named Atheria. Unlike ordinary backpacks, Atheria held a secret that set her apart from the rest. Woven with ancient runes and imbued with potent enchantment, she possessed the ability to grant wishes.\n",
            "\n",
            "Emily, a curious and imaginative 12-year-old, stumbled upon Atheria in the attic of her grandmother's old house. As she unzipped her compartments, a soft glow illuminated the room, enveloping Emily in a wave of awe and wonder.\n",
            "\n",
            "\"What is your name?\" Emily whispered.\n",
            "\n",
            "\"Atheria,\" the backpack replied in a melodious voice. \"I have the power to fulfill your wishes.\"\n",
            "\n",
            "Emily's heart skipped a beat. She had never imagined such a thing was possible. Filled with excitement, she began to make wishes, her imagination soaring.\n",
            "\n",
            "\"I wish for the most delicious ice cream,\" Emily said.\n",
            "\n",
            "Instantly, Atheria transformed into a cooler, stocked with an assortment of delectable treats. Emily couldn't resist indulging in a scoop of strawberry sorbet, its sweetness melting in her mouth.\n",
            "\n",
            "As the sun began to set, Emily faced a dilemma. She had promised her friends she would join them for a movie, but her parents had forbidden her from going out. Desperation crept into her eyes.\n",
            "\n",
            "\"Atheria, can you help me?\" she pleaded.\n",
            "\n",
            "\"I wish I could go to the movies,\" Emily whispered.\n",
            "\n",
            "To Emily's astonishment, Atheria's zipper opened, revealing a miniature cinema. Plush seats, a giant screen, and the latest animated film filled the space. Emily and her friends laughed and cheered, their worries melting away with every frame.\n",
            "\n",
            "However, with great power came great responsibility. Atheria warned Emily that her wishes must be well-considered and used wisely. Emily took the lesson to heart, using her newfound power to spread joy and make the world a better place.\n",
            "\n",
            "One day, a devastating fire broke out in the town. Emily, armed with Atheria, rushed to the scene. She wished for an endless stream of water to quench the flames and protect the houses.\n",
            "\n",
            "As the flames subsided, the townspeople erupted in cheers, hailing Emily as their savior. From that day forward, Emily became known as the \"Guardian of Willow Creek,\" the girl with the magic backpack who had used her wishes to bring happiness and safety to her beloved town.\n",
            "\n",
            "And so, Atheria and Emily's adventures continued, their bond unbreakable. Together, they proved that even the simplest of objects could hold extraordinary power, capable of shaping destinies and transforming lives.\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fRbNtt4jV6uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install streamlit pandas htmlmin rcssmin jsmin pillow beautifulsoup4 requests crewai langchain google-generativeai wikipedia-api python-dotenv aiohttp html5lib"
      ],
      "metadata": {
        "id": "yDp26pUZV6rf",
        "outputId": "5de2243b-11bc-428e-aa52-1f210d5063c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting htmlmin\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rcssmin\n",
            "  Downloading rcssmin-1.1.3-cp310-cp310-manylinux1_x86_64.whl.metadata (4.6 kB)\n",
            "Collecting jsmin\n",
            "  Downloading jsmin-3.0.1.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Collecting crewai\n",
            "  Downloading crewai-0.76.2-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n",
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting auth0-python>=4.7.1 (from crewai)\n",
            "  Downloading auth0_python-4.7.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting chromadb>=0.4.24 (from crewai)\n",
            "  Downloading chromadb-0.5.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting crewai-tools>=0.13.2 (from crewai)\n",
            "  Downloading crewai_tools-0.13.2-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.6.3-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting json-repair>=0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.30.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting litellm>=1.44.22 (from crewai)\n",
            "  Downloading litellm-1.50.4-py3-none-any.whl.metadata (32 kB)\n",
            "Collecting openai>=1.13.3 (from crewai)\n",
            "  Downloading openai-1.52.2-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting opentelemetry-api>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk>=1.22.0 (from crewai)\n",
            "  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pydantic>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from crewai) (2.9.2)\n",
            "Collecting pyvis>=0.3.2 (from crewai)\n",
            "  Downloading pyvis-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.10/dist-packages (from crewai) (2024.9.11)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.1.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.4.26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.4.0,>=0.3.12 (from langchain)\n",
            "  Downloading langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.137.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.24.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.16.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: cryptography<44.0.0,>=43.0.1 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (43.0.3)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from auth0-python>=4.7.1->crewai) (2.9.0)\n",
            "Collecting build>=1.0.3 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading fastapi-0.115.3-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting overrides>=7.3.1 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb>=0.4.24->crewai) (0.12.5)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.27.0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting docker>=7.1.0 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting docx2txt>=0.8 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting embedchain>=0.1.114 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading embedchain-0.1.123-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting lancedb>=0.5.4 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading lancedb-0.14.0-cp38-abi3-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting pyright>=1.1.350 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pyright-1.1.386-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting pytest>=8.0.0 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pytube>=15.0.0 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting selenium>=4.18.1 (from crewai-tools>=0.13.2->crewai)\n",
            "  Downloading selenium-4.25.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: docstring-parser<0.17,>=0.16 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (0.16)\n",
            "Collecting jiter<0.6.0,>=0.5.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from instructor>=1.3.3->crewai) (2.23.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.10/dist-packages (from litellm>=1.44.22->crewai) (8.5.0)\n",
            "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.13.3->crewai) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.13.3->crewai) (1.3.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->crewai) (1.2.14)\n",
            "Collecting importlib-metadata>=6.8.0 (from litellm>=1.44.22->crewai)\n",
            "  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-sdk>=1.22.0->crewai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.4.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (7.34.0)\n",
            "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (3.3.0)\n",
            "Requirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from pyvis>=0.3.2->crewai) (3.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.13.3->crewai) (1.2.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb>=0.4.24->crewai) (2.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (1.17.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->crewai) (1.16.0)\n",
            "Collecting alembic<2.0.0,>=1.13.1 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading alembic-1.13.3-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting chromadb>=0.4.24 (from crewai)\n",
            "  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting cohere<6.0,>=5.3 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading cohere-5.11.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.26.1 in /usr/local/lib/python3.10/dist-packages (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (1.70.0)\n",
            "Collecting gptcache<0.2.0,>=0.1.43 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting langchain-cohere<0.4.0,>=0.3.0 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading langchain_cohere-0.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting langchain-community<0.4.0,>=0.3.1 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-openai<0.3.0,>=0.2.1 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting mem0ai<0.2.0,>=0.1.18 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading mem0ai-0.1.23-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypdf<6.0.0,>=5.0.0 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pypdf-5.0.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pysbd<0.4.0,>=0.3.4 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting schema<0.8.0,>=0.7.5 (from embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading schema-0.7.7-py2.py3-none-any.whl.metadata (34 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm>=1.44.22->crewai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting pulsar-client>=3.1.0 (from chromadb>=0.4.24->crewai)\n",
            "  Downloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb>=0.4.24->crewai)\n",
            "  Downloading starlette-0.41.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
            "Collecting httpcore==1.* (from httpx>=0.27.0->chromadb>=0.4.24->crewai)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.27.0->chromadb>=0.4.24->crewai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai) (3.20.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.3.0->pyvis>=0.3.2->crewai)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (3.0.48)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.12->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai) (3.2.2)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb>=0.4.24->crewai)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Collecting deprecation (from lancedb>=0.5.4->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting pylance==0.18.2 (from lancedb>=0.5.4->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pylance-0.18.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting retry>=0.9.2 (from lancedb>=0.5.4->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading retry-0.9.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb>=0.4.24->crewai) (1.13.1)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
            "  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
            "  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.4.24->crewai)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb>=0.4.24->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Collecting nodeenv>=1.6.0 (from pyright>=1.1.350->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools>=0.13.2->crewai) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.0.0->crewai-tools>=0.13.2->crewai) (1.5.0)\n",
            "Collecting trio~=0.17 (from selenium>=4.18.1->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading trio-0.27.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium>=4.18.1->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (0.24.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb>=0.4.24->crewai) (1.5.4)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb>=0.4.24->crewai)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting Mako (from alembic<2.0.0,>=1.13.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading Mako-1.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography<44.0.0,>=43.0.1->auth0-python>=4.7.1->crewai) (2.22)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting parameterized<0.10.0,>=0.9.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading parameterized-0.9.0-py2.py3-none-any.whl.metadata (18 kB)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.3->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (1.12.5)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (2.0.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.4.24->crewai) (2024.6.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.8.4)\n",
            "Collecting langchain-experimental>=0.3.0 (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from langchain-cohere<0.4.0,>=0.3.0->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (0.9.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading pydantic_settings-2.6.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting qdrant-client<2.0.0,>=1.9.1 (from mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading qdrant_client-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis>=0.3.2->crewai) (0.2.13)\n",
            "Collecting py<2.0.0,>=1.4.26 (from retry>=0.9.2->lancedb>=0.5.4->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading py-1.11.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting outcome (from trio~=0.17->selenium>=4.18.1->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium>=4.18.1->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium>=4.18.1->crewai-tools>=0.13.2->crewai) (1.7.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.4.24->crewai) (1.3.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (2.7.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (0.13.1)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading grpcio_tools-1.67.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.26.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai) (1.6.0)\n",
            "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading grpcio_tools-1.66.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.66.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.65.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading grpcio_tools-1.64.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting protobuf<6,>=3.20 (from streamlit)\n",
            "  Downloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.1->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.9.1->mem0ai<0.2.0,>=0.1.18->embedchain>=0.1.114->crewai-tools>=0.13.2->crewai)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rcssmin-1.1.3-cp310-cp310-manylinux1_x86_64.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai-0.76.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading auth0_python-4.7.2-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading crewai_tools-0.13.2-py3-none-any.whl (463 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m463.4/463.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.6.3-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.30.0-py3-none-any.whl (17 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m407.7/407.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litellm-1.50.4-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.52.2-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyvis-0.3.2-py3-none-any.whl (756 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m756.0/756.0 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.1.0-py3-none-any.whl (6.4 kB)\n",
            "Downloading uv-0.4.26-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embedchain-0.1.123-py3-none-any.whl (210 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.9/210.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.3-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lancedb-0.14.0-cp38-abi3-manylinux_2_28_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pylance-0.18.2-cp39-abi3-manylinux_2_28_x86_64.whl (30.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30.0/30.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading orjson-3.10.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pulsar_client-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyright-1.1.386-py3-none-any.whl (18 kB)\n",
            "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m342.3/342.3 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading selenium-4.25.0-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.3-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.2/233.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cohere-5.11.1-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m249.7/249.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading langchain_cohere-0.3.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.3-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mem0ai-0.1.23-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading pypdf-5.0.1-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retry-0.9.2-py2.py3-none-any.whl (8.0 kB)\n",
            "Downloading schema-0.7.7-py2.py3-none-any.whl (18 kB)\n",
            "Downloading starlette-0.41.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.27.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m481.7/481.7 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m208.1/208.1 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n",
            "Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.6.0-py3-none-any.whl (28 kB)\n",
            "Downloading qdrant_client-1.12.0-py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m266.4/266.4 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading Mako-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading grpcio_tools-1.62.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.5-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: htmlmin, jsmin, wikipedia-api, docx2txt, pypika\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=fdf561846aca8fb94c8af690507fe73f81f58bf5cb2c303ed366fa8b07a7c32a\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "  Building wheel for jsmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsmin: filename=jsmin-3.0.1-py3-none-any.whl size=13763 sha256=cba018bc75ef356582804c7ef4f32c3acd4eb007c5744735de1cbfb7bf353a53\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/eb/65/4a07a200d454fb40cbd51a2deee3c5d26285321e3bbbe627a5\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14346 sha256=86eb5d7a0559d7d8b19ac7777d016a8cf5047d2588d990c09670dd30b8bc06f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=35d315498401c0cbf2dac628cfbf6b433f0463134cbbd67768547f74633afba6\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=3d7663cb623bcbfefa992a72ab5ba3a7474fe677c3876822ddf2468e811cc394\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built htmlmin jsmin wikipedia-api docx2txt pypika\n",
            "Installing collected packages: sortedcontainers, schema, rcssmin, pypika, monotonic, jsmin, htmlmin, durationpy, docx2txt, appdirs, websockets, watchdog, uvloop, uv, types-requests, tomli-w, pytube, python-dotenv, pytest, pysbd, pyproject_hooks, pypdf, py, pulsar-client, protobuf, portalocker, parameterized, overrides, outcome, orjson, opentelemetry-util-http, nodeenv, mypy-extensions, mmh3, marshmallow, Mako, jsonref, jsonpointer, json-repair, jiter, jedi, importlib-metadata, hyperframe, humanfriendly, httpx-sse, httptools, hpack, h11, fastavro, deprecation, chroma-hnswlib, bcrypt, backoff, asgiref, wsproto, wikipedia-api, watchfiles, uvicorn, typing-inspect, trio, tiktoken, starlette, retry, requests-toolbelt, pyright, pylance, pydeck, posthog, opentelemetry-proto, opentelemetry-api, jsonpatch, httpcore, h2, grpcio-tools, gptcache, docker, coloredlogs, build, alembic, trio-websocket, pyvis, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-common, onnxruntime, lancedb, kubernetes, httpx, fastapi, dataclasses-json, selenium, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langsmith, cohere, auth0-python, streamlit, qdrant-client, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, litellm, langchain-core, instructor, mem0ai, langchain-text-splitters, langchain-openai, chromadb, langchain, langchain-community, langchain-experimental, langchain-cohere, embedchain, crewai-tools, crewai\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.5.0\n",
            "    Uninstalling importlib_metadata-8.5.0:\n",
            "      Successfully uninstalled importlib_metadata-8.5.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.6 alembic-1.13.3 appdirs-1.4.4 asgiref-3.8.1 auth0-python-4.7.2 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2.post1 chroma-hnswlib-0.7.3 chromadb-0.4.24 cohere-5.11.1 coloredlogs-15.0.1 crewai-0.76.2 crewai-tools-0.13.2 dataclasses-json-0.6.7 deprecation-2.1.0 docker-7.1.0 docx2txt-0.8 durationpy-0.9 embedchain-0.1.123 fastapi-0.115.3 fastavro-1.9.7 gptcache-0.1.44 grpcio-tools-1.62.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 htmlmin-0.1.12 httpcore-1.0.6 httptools-0.6.4 httpx-0.27.2 httpx-sse-0.4.0 humanfriendly-10.0 hyperframe-6.0.1 importlib-metadata-8.4.0 instructor-1.6.3 jedi-0.19.1 jiter-0.5.0 jsmin-3.0.1 json-repair-0.30.0 jsonpatch-1.33 jsonpointer-3.0.0 jsonref-1.1.0 kubernetes-31.0.0 lancedb-0.14.0 langchain-0.3.4 langchain-cohere-0.3.1 langchain-community-0.3.3 langchain-core-0.3.12 langchain-experimental-0.3.2 langchain-openai-0.2.3 langchain-text-splitters-0.3.0 langsmith-0.1.137 litellm-1.50.4 marshmallow-3.23.0 mem0ai-0.1.23 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 nodeenv-1.9.1 onnxruntime-1.19.2 openai-1.52.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-exporter-otlp-proto-http-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.10 outcome-1.3.0.post0 overrides-7.7.0 parameterized-0.9.0 portalocker-2.10.1 posthog-3.7.0 protobuf-4.25.5 pulsar-client-3.5.0 py-1.11.0 pydantic-settings-2.6.0 pydeck-0.9.1 pylance-0.18.2 pypdf-5.0.1 pypika-0.48.9 pyproject_hooks-1.2.0 pyright-1.1.386 pysbd-0.3.4 pytest-8.3.3 python-dotenv-1.0.1 pytube-15.0.0 pyvis-0.3.2 qdrant-client-1.12.0 rcssmin-1.1.3 requests-toolbelt-1.0.0 retry-0.9.2 schema-0.7.7 selenium-4.25.0 sortedcontainers-2.4.0 starlette-0.41.0 streamlit-1.39.0 tiktoken-0.7.0 tomli-w-1.1.0 trio-0.27.0 trio-websocket-0.11.1 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uv-0.4.26 uvicorn-0.32.0 uvloop-0.21.0 watchdog-5.0.3 watchfiles-0.24.0 websockets-13.1 wikipedia-api-0.7.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "DCk2sQJDXYA_",
        "outputId": "65f5d2c2-e767-4b9a-b629-a69651204d33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "WQyqFjxOYuuB",
        "outputId": "59487e3b-45ac-4fe6-82b6-a84d9c89ea64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=e4887715551ee3338a6fb51def1eb62b884d1ca3b82177bb8b3e64bf6250e411\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# config.py\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyA5HtRnzGruiia-aKtMMLnBjJ0ovTh11nE\"\n",
        "\n",
        "WIKIPEDIA_USER_AGENT = \"WebsiteBuilderBot/1.0\"\n",
        "\n",
        "# Theme configuration\n",
        "CLAUDE_COLORS = {\n",
        "    'primary': '#FF6B3D',\n",
        "    'secondary': '#FF8F6B',\n",
        "    'background': '#FFFFFF',\n",
        "    'text': '#1A1A1A',\n",
        "    'accent': '#FFE4DC'\n",
        "}\n",
        "\n",
        "\n",
        "# main.py\n",
        "CUSTOM_CSS = \"\"\"\n",
        "<style>\n",
        "/* Global styles */\n",
        "body {\n",
        "    font-family: 'Roboto', sans-serif;\n",
        "    background-color: #F5F5F5;\n",
        "    color: #333;\n",
        "    line-height: 1.6;\n",
        "    margin: 0;\n",
        "}\n",
        "\n",
        "/* Header styles */\n",
        "h1 {\n",
        "    color: #FF5722;\n",
        "    text-align: center;\n",
        "    margin-bottom: 1.5rem;\n",
        "}\n",
        "\n",
        "/* Sidebar styles */\n",
        ".sidebar .stButton button {\n",
        "    background-color: #FF7043;\n",
        "    color: #fff;\n",
        "    border-radius: 8px;\n",
        "    border: none;\n",
        "    transition: background-color 0.3s ease;\n",
        "}\n",
        "\n",
        ".sidebar .stButton button:hover {\n",
        "    background-color: #E64A19;\n",
        "}\n",
        "\n",
        "/* Custom button styles */\n",
        ".stButton>button {\n",
        "    background-color: #4CAF50;\n",
        "    color: white;\n",
        "    padding: 0.75rem 1.25rem;\n",
        "    border-radius: 6px;\n",
        "    border: none;\n",
        "    cursor: pointer;\n",
        "    transition: background-color 0.3s ease;\n",
        "    font-size: 16px;\n",
        "}\n",
        "\n",
        ".stButton>button:hover {\n",
        "    background-color: #388E3C;\n",
        "}\n",
        "\n",
        "/* Input field styles */\n",
        ".stTextInput>div>input {\n",
        "    border: 1px solid #BDBDBD;\n",
        "    border-radius: 5px;\n",
        "    padding: 0.5rem;\n",
        "    font-size: 15px;\n",
        "}\n",
        "\n",
        "/* Streamlit container modifications */\n",
        ".reportview-container .main .block-container {\n",
        "    padding-top: 2rem;\n",
        "    padding-bottom: 2rem;\n",
        "    padding-left: 2rem;\n",
        "    padding-right: 2rem;\n",
        "    border-radius: 10px;\n",
        "    background-color: #FFFFFF;\n",
        "    box-shadow: 0px 4px 10px rgba(0, 0, 0, 0.1);\n",
        "}\n",
        "\n",
        "/* Footer modifications */\n",
        "footer {\n",
        "    text-align: center;\n",
        "    padding: 1rem 0;\n",
        "    font-size: 0.85rem;\n",
        "    color: #888;\n",
        "}\n",
        "\n",
        "/* Scrollbar styles */\n",
        "::-webkit-scrollbar {\n",
        "    width: 8px;\n",
        "}\n",
        "\n",
        "::-webkit-scrollbar-track {\n",
        "    background: #F0F0F0;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "\n",
        "::-webkit-scrollbar-thumb {\n",
        "    background: #FF5722;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# agents/base_agent.py\n",
        "from abc import ABC, abstractmethod\n",
        "import google.generativeai as genai\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "import logging\n",
        "import streamlit as st\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import wikipedia # Importing wikipedia after installation\n",
        "\n",
        "class WikipediaAPIWrapper:\n",
        "    def fetch_wikipedia_summary(query):\n",
        "        wikipedia.set_lang(\"en\")\n",
        "        try:\n",
        "            summary = wikipedia.summary(query, sentences=2)\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            # Add error handling here\n",
        "            logging.error(f\"Error fetching Wikipedia summary: {e}\")  # Log the error\n",
        "            return None  # or raise the exception again: raise e\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BaseAgent(ABC):\n",
        "    def __init__(self, model: Any, temperature: float = 0.7):\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "    def generate_response(self, prompt: str) -> str:\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    @abstractmethod\n",
        "    def process(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "# agents/label_creator_agent.py\n",
        "class LabelCreatorAgent(BaseAgent):\n",
        "    def process(self, user_prompt: str) -> Dict:\n",
        "        self.logger.info(\"Creating labels from user prompt\")\n",
        "        prompt = f\"\"\"\n",
        "        Analyze and create detailed labels for website requirements:\n",
        "        {user_prompt}\n",
        "\n",
        "        Generate a comprehensive JSON structure with:\n",
        "        1. Page Structure:\n",
        "           - Layout components\n",
        "           - Navigation elements\n",
        "           - Content sections\n",
        "        2. Design Requirements:\n",
        "           - Color scheme\n",
        "           - Typography\n",
        "           - Spacing and layout rules\n",
        "        3. Functionality:\n",
        "           - Interactive elements\n",
        "           - Forms and inputs\n",
        "           - Dynamic features\n",
        "        4. Content Requirements:\n",
        "           - Text sections\n",
        "           - Media elements\n",
        "           - Data requirements\n",
        "        5. Technical Specifications:\n",
        "           - Required libraries\n",
        "           - API integrations\n",
        "           - Performance requirements\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.generate_response(prompt)\n",
        "            return json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing JSON response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# agents/task_distributor_agent.py\n",
        "class TaskDistributorAgent(BaseAgent):\n",
        "    def process(self, labels: Dict) -> List[Dict]:\n",
        "        self.logger.info(\"Distributing tasks based on labels\")\n",
        "        prompt = f\"\"\"\n",
        "        Create a detailed task distribution plan for:\n",
        "        {json.dumps(labels, indent=2)}\n",
        "\n",
        "        Generate tasks for:\n",
        "        1. Frontend Development:\n",
        "           - Component creation\n",
        "           - Styling implementation\n",
        "           - Responsive design\n",
        "        2. Backend Integration:\n",
        "           - API endpoints\n",
        "           - Data processing\n",
        "           - Security features\n",
        "        3. Content Generation:\n",
        "           - Text content\n",
        "           - Media assets\n",
        "           - SEO elements\n",
        "        4. Testing Requirements:\n",
        "           - Unit tests\n",
        "           - Integration tests\n",
        "           - Performance testing\n",
        "\n",
        "        Return as JSON array with task details, dependencies, and priorities.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.generate_response(prompt)\n",
        "            return json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing JSON response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# agents/coding_agent.py\n",
        "class CodingAgent(BaseAgent):\n",
        "    def process(self, task: Dict) -> Dict:\n",
        "        self.logger.info(f\"Generating code for task: {task.get('name', 'Unknown')}\")\n",
        "        prompt = f\"\"\"\n",
        "        Generate production-ready code for:\n",
        "        {json.dumps(task, indent=2)}\n",
        "\n",
        "        Include:\n",
        "        1. Complete component code\n",
        "        2. Styling (CSS/SCSS)\n",
        "        3. JavaScript functionality\n",
        "        4. Error handling\n",
        "        5. Documentation\n",
        "        6. Performance optimizations\n",
        "\n",
        "        Follow best practices for:\n",
        "        - Clean code\n",
        "        - Accessibility\n",
        "        - SEO\n",
        "        - Performance\n",
        "        \"\"\"\n",
        "        try:\n",
        "            code_response = self.generate_response(prompt)\n",
        "            return {\n",
        "                \"task\": task,\n",
        "                \"code\": code_response,\n",
        "                \"metadata\": {\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"version\": \"1.0\"\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating code: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# agents/design_agent.py\n",
        "class DesignAgent(BaseAgent):\n",
        "    def process(self, labels: Dict) -> Dict:\n",
        "        self.logger.info(\"Generating design system\")\n",
        "        prompt = f\"\"\"\n",
        "        Create a comprehensive design system based on:\n",
        "        {json.dumps(labels, indent=2)}\n",
        "\n",
        "        Include:\n",
        "        1. Color Palette:\n",
        "           - Primary colors\n",
        "           - Secondary colors\n",
        "           - Accent colors\n",
        "           - Semantic colors\n",
        "        2. Typography:\n",
        "           - Font families\n",
        "           - Font sizes\n",
        "           - Line heights\n",
        "           - Font weights\n",
        "        3. Spacing System:\n",
        "           - Grid system\n",
        "           - Margins\n",
        "           - Paddings\n",
        "        4. Component Styles:\n",
        "           - Buttons\n",
        "           - Forms\n",
        "           - Cards\n",
        "           - Navigation\n",
        "        5. Animation Guidelines:\n",
        "           - Transitions\n",
        "           - Hover states\n",
        "           - Loading states\n",
        "        \"\"\"\n",
        "        try:\n",
        "            design_response = self.generate_response(prompt)\n",
        "            return json.loads(design_response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing design system JSON: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# agents/upgrading_agent.py\n",
        "class UpgradingAgent(BaseAgent):\n",
        "    def process(self, component: Dict) -> Dict:\n",
        "        self.logger.info(f\"Upgrading component: {component.get('task', {}).get('name', 'Unknown')}\")\n",
        "        prompt = f\"\"\"\n",
        "        Optimize and upgrade the following component:\n",
        "        {json.dumps(component, indent=2)}\n",
        "\n",
        "        Focus on:\n",
        "        1. Performance Optimization:\n",
        "           - Code splitting\n",
        "           - Lazy loading\n",
        "           - Resource optimization\n",
        "        2. Security Improvements:\n",
        "           - Input validation\n",
        "           - XSS prevention\n",
        "           - CSRF protection\n",
        "        3. Accessibility Enhancements:\n",
        "           - ARIA labels\n",
        "           - Keyboard navigation\n",
        "           - Screen reader support\n",
        "        4. SEO Optimization:\n",
        "           - Meta tags\n",
        "           - Semantic HTML\n",
        "           - Schema markup\n",
        "        \"\"\"\n",
        "        try:\n",
        "            upgraded_code = self.generate_response(prompt)\n",
        "            return {\n",
        "                \"task\": component[\"task\"],\n",
        "                \"original_code\": component[\"code\"],\n",
        "                \"upgraded_code\": upgraded_code,\n",
        "                \"upgrade_metadata\": {\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"version\": \"1.1\"\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error upgrading component: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# agents/verification_agent.py\n",
        "class VerificationAgent(BaseAgent):\n",
        "    def process(self, website_data: Dict) -> Dict:\n",
        "        self.logger.info(\"Verifying website components and integration\")\n",
        "        prompt = f\"\"\"\n",
        "        Perform comprehensive verification of:\n",
        "        {json.dumps(website_data, indent=2)}\n",
        "\n",
        "        Check for:\n",
        "        1. Code Quality:\n",
        "           - Syntax validation\n",
        "           - Best practices\n",
        "           - Code standards\n",
        "        2. Integration:\n",
        "           - Component compatibility\n",
        "           - API integration\n",
        "           - State management\n",
        "        3. Performance:\n",
        "           - Load time optimization\n",
        "           - Resource usage\n",
        "           - Memory leaks\n",
        "        4. Security:\n",
        "           - Vulnerability scanning\n",
        "           - Input validation\n",
        "           - Authentication checks\n",
        "        5. Accessibility:\n",
        "           - WCAG compliance\n",
        "           - Screen reader compatibility\n",
        "           - Keyboard navigation\n",
        "        \"\"\"\n",
        "        try:\n",
        "            verification_response = self.generate_response(prompt)\n",
        "            return json.loads(verification_response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing verification results: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "# utils/wiki_content_generator.py\n",
        "class WikiContentGenerator:\n",
        "    def __init__(self, wikipedia_api_wrapper):\n",
        "        self.wiki = wikipedia_api_wrapper\n",
        "\n",
        "    def generate_content(self, topic: str) -> Dict:\n",
        "        try:\n",
        "            search_results = self.wiki.search(topic)\n",
        "            content = []\n",
        "            for result in search_results[:3]:\n",
        "                try:\n",
        "                    page = self.wiki.page(result)\n",
        "                    content.append({\n",
        "                        \"title\": page.title,\n",
        "                        \"summary\": page.summary,\n",
        "                        \"url\": page.url\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error fetching wiki page {result}: {str(e)}\")\n",
        "                    continue\n",
        "            return {\"status\": \"success\", \"content\": content}\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in wiki content generation: {str(e)}\")\n",
        "            return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "# website_builder.py\n",
        "class WebsiteBuilder:\n",
        "    def __init__(self):\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        self.agents = {\n",
        "            \"label_creator\": LabelCreatorAgent(self.model),\n",
        "            \"task_distributor\": TaskDistributorAgent(self.model),\n",
        "            \"coding\": CodingAgent(self.model),\n",
        "            \"upgrading\": UpgradingAgent(self.model),\n",
        "            \"design\": DesignAgent(self.model),\n",
        "            \"verification\": VerificationAgent(self.model)\n",
        "        }\n",
        "        self.wiki_generator = WikiContentGenerator(WikipediaAPIWrapper())\n",
        "        self.logger = logging.getLogger(\"WebsiteBuilder\")\n",
        "\n",
        "    def build_website(self, user_prompt: str) -> Dict:\n",
        "        try:\n",
        "            # 1. Create labels\n",
        "            self.logger.info(\"Step 1: Creating labels\")\n",
        "            labels = self.agents[\"label_creator\"].process(user_prompt)\n",
        "\n",
        "            # 2. Generate content from Wikipedia if needed\n",
        "            if \"content_requirements\" in labels:\n",
        "                self.logger.info(\"Generating content from Wikipedia\")\n",
        "                for topic in labels[\"content_requirements\"]:\n",
        "                    wiki_content = self.wiki_generator.generate_content(topic)\n",
        "                    labels[\"wiki_content\"] = wiki_content\n",
        "\n",
        "            # 3. Create design system\n",
        "            self.logger.info(\"Step 2: Creating design system\")\n",
        "            design_system = self.agents[\"design\"].process(labels)\n",
        "\n",
        "            # 4. Distribute tasks\n",
        "            self.logger.info(\"Step 3: Distributing tasks\")\n",
        "            tasks = self.agents[\"task_distributor\"].process(labels)\n",
        "\n",
        "            # 5. Generate components in parallel\n",
        "            self.logger.info(\"Step 4: Generating components\")\n",
        "            components = []\n",
        "            for task in tasks:\n",
        "                component = self.agents[\"coding\"].process(task)\n",
        "                components.append(component)\n",
        "\n",
        "            # 6. Upgrade components\n",
        "            self.logger.info(\"Step 5: Upgrading components\")\n",
        "            upgraded_components = []\n",
        "            for component in components:\n",
        "                upgraded = self.agents[\"upgrading\"].process(component)\n",
        "                upgraded_components.append(upgraded)\n",
        "\n",
        "            # 7. Verify website\n",
        "            self.logger.info(\"Step 6: Verifying website\")\n",
        "            verification_results = self.agents[\"verification\"].process({\n",
        "                \"components\": upgraded_components,\n",
        "                \"design_system\": design_system,\n",
        "                \"labels\": labels\n",
        "            })\n",
        "\n",
        "            # 8. Generate preview HTML\n",
        "            preview_html = self.generate_preview_html(upgraded_components, design_system)\n",
        "\n",
        "            return {\n",
        "                \"status\": \"success\",\n",
        "                \"labels\": labels,\n",
        "                \"design_system\": design_system,\n",
        "                \"components\": upgraded_components,\n",
        "                \"verification\": verification_results,\n",
        "                \"preview_html\": preview_html\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error building website: {str(e)}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"message\": str(e)\n",
        "            }\n",
        "\n",
        "    def generate_preview_html(self, components: List[Dict], design_system: Dict) -> str:\n",
        "        # [Previous generate_preview_html code remains the same]\n",
        "        pass\n",
        "\n",
        "# main.py\n",
        "def main():\n",
        "    st.set_page_config(page_title=\"AI Website Builder\", layout=\"wide\")\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'build_history' not in st.session_state:\n",
        "        st.session_state.build_history = []\n",
        "\n",
        "    if 'current_build' not in st.session_state:\n",
        "        st.session_state.current_build = None\n",
        "\n",
        "    # Inject custom CSS\n",
        "    st.markdown(CUSTOM_CSS, unsafe_allow_html=True)\n",
        "\n",
        "    # Sidebar\n",
        "    with st.sidebar:\n",
        "        st.markdown(f'''\n",
        "        <div style=\"background-color: {CLAUDE_COLORS[\"accent\"]}; padding: 1rem; border-radius: 4px;\">\n",
        "            <h2>Configuration</h2>\n",
        "        </div>\n",
        "        ''', unsafe_allow_html=True)\n",
        "\n",
        "        # Build History\n",
        "        if st.session_state.build_history:\n",
        "            st.subheader(\"Build History\")\n",
        "            for idx, build in enumerate(st.session_state.build_history):\n",
        "                if st.button(f\"Build {idx + 1}\", key=f\"build_{idx}\"):\n",
        "                    st.session_state.current_build = build\n",
        "\n",
        "    # Main content area\n",
        "    st.title(\"AI Website Builder\")\n",
        "\n",
        "    # Three-column layout\n",
        "    col1, col2, col3 = st.columns([1, 1, 1])\n",
        "\n",
        "    with col1:\n",
        "        st.subheader(\"Website Requirements\")\n",
        "        user_prompt = st.text_area(\"Describe your website\", height=200)\n",
        "\n",
        "        if st.button(\"Generate Website\", type=\"primary\"):\n",
        "            if user_prompt:\n",
        "                with st.spinner(\"Building your website...\"):\n",
        "                    builder = WebsiteBuilder()\n",
        "                    result = builder.build_website(user_prompt)\n",
        "\n",
        "                    if result[\"status\"] == \"success\":\n",
        "                        st.session_state.current_build = result\n",
        "                        st.session_state.build_history.append(result)\n",
        "                        st.success(\"Website generated successfully!\")\n",
        "                    else:\n",
        "                        st.error(f\"Error: {result['message']}\")\n",
        "            else:\n",
        "                st.error(\"Please provide website requirements\")\n",
        "\n",
        "    # Display current build\n",
        "    if st.session_state.current_build:\n",
        "        # Code Column\n",
        "        with col2:\n",
        "            st.subheader(\"Generated Code\")\n",
        "            tabs = st.tabs([\"Components\", \"Design System\", \"Verification\"])\n",
        "\n",
        "            with tabs[0]:\n",
        "                for idx, component in enumerate(st.session_state.current_build[\"components\"]):\n",
        "                    with st.expander(f\"Component {idx + 1}\"):\n",
        "                        st.code(component[\"upgraded_code\"], language=\"html\")\n",
        "                        if st.button(f\"Download Component {idx + 1}\", key=f\"download_comp_{idx}\"):\n",
        "                            st.download_button(\n",
        "                                label=f\"Download Component {idx + 1}\",\n",
        "                                data=component[\"upgraded_code\"],\n",
        "                                file_name=f\"component_{idx + 1}.html\",\n",
        "                                mime=\"text/html\"\n",
        "                            )\n",
        "\n",
        "            with tabs[1]:\n",
        "                st.json(st.session_state.current_build[\"design_system\"])\n",
        "\n",
        "            with tabs[2]:\n",
        "                # Continuing from the previous code...\n",
        "\n",
        "                st.json(st.session_state.current_build[\"verification\"])\n",
        "\n",
        "        # Preview Column\n",
        "        with col3:\n",
        "            st.subheader(\"Live Preview\")\n",
        "            preview_container = st.container()\n",
        "\n",
        "            # Preview controls\n",
        "            col3_1, col3_2, col3_3 = st.columns(3)\n",
        "            with col3_1:\n",
        "                preview_device = st.selectbox(\n",
        "                    \"Preview Device\",\n",
        "                    [\"Desktop\", \"Tablet\", \"Mobile\"]\n",
        "                )\n",
        "\n",
        "            with col3_2:\n",
        "                preview_theme = st.selectbox(\n",
        "                    \"Preview Theme\",\n",
        "                    [\"Light\", \"Dark\"]\n",
        "                )\n",
        "\n",
        "            with col3_3:\n",
        "                if st.button(\"Refresh Preview\"):\n",
        "                    st.experimental_rerun()\n",
        "\n",
        "            # Preview window\n",
        "            preview_html = st.session_state.current_build[\"preview_html\"]\n",
        "\n",
        "            # Adjust preview based on device selection\n",
        "            preview_width = {\n",
        "                \"Desktop\": \"100%\",\n",
        "                \"Tablet\": \"768px\",\n",
        "                \"Mobile\": \"375px\"\n",
        "            }[preview_device]\n",
        "\n",
        "            # Apply theme to preview\n",
        "            if preview_theme == \"Dark\":\n",
        "                preview_html = preview_html.replace(\n",
        "                    'background-color: var(--background-color)',\n",
        "                    'background-color: #1a1a1a; color: #ffffff'\n",
        "                )\n",
        "\n",
        "            # Display preview\n",
        "            components.html(\n",
        "                f\"\"\"\n",
        "                <div style=\"width: {preview_width}; margin: 0 auto; border: 1px solid #ddd; border-radius: 4px; overflow: hidden;\">\n",
        "                    {preview_html}\n",
        "                </div>\n",
        "                \"\"\",\n",
        "                height=600,\n",
        "                scrolling=True\n",
        "            )\n",
        "\n",
        "            # Export options\n",
        "            st.subheader(\"Export Options\")\n",
        "            export_cols = st.columns(2)\n",
        "\n",
        "            with export_cols[0]:\n",
        "                if st.button(\"Download Complete Website\"):\n",
        "                    # Create zip file containing all components\n",
        "                    with ZipFile(\"website.zip\", \"w\") as zipf:\n",
        "                        # Add HTML file\n",
        "                        zipf.writestr(\"index.html\", preview_html)\n",
        "\n",
        "                        # Add CSS\n",
        "                        css = st.session_state.current_build[\"design_system\"].get(\"css\", \"\")\n",
        "                        zipf.writestr(\"styles.css\", css)\n",
        "\n",
        "                        # Add JavaScript\n",
        "                        js = st.session_state.current_build[\"design_system\"].get(\"javascript\", \"\")\n",
        "                        zipf.writestr(\"scripts.js\", js)\n",
        "\n",
        "                        # Add components\n",
        "                        for idx, component in enumerate(st.session_state.current_build[\"components\"]):\n",
        "                            zipf.writestr(\n",
        "                                f\"components/component_{idx + 1}.html\",\n",
        "                                component[\"upgraded_code\"]\n",
        "                            )\n",
        "\n",
        "                    # Provide download button\n",
        "                    with open(\"website.zip\", \"rb\") as f:\n",
        "                        st.download_button(\n",
        "                            label=\"Download ZIP\",\n",
        "                            data=f,\n",
        "                            file_name=\"website.zip\",\n",
        "                            mime=\"application/zip\"\n",
        "                        )\n",
        "\n",
        "            with export_cols[1]:\n",
        "                if st.button(\"Export to GitHub\"):\n",
        "                    st.info(\"GitHub export functionality coming soon!\")\n",
        "\n",
        "# Add utility functions\n",
        "def create_github_repository(components: List[Dict], design_system: Dict) -> str:\n",
        "    \"\"\"Create a GitHub repository with the generated website code\"\"\"\n",
        "    # Implementation for GitHub integration\n",
        "    pass\n",
        "\n",
        "def optimize_images(html_content: str) -> str:\n",
        "    \"\"\"Optimize images in the HTML content\"\"\"\n",
        "    from bs4 import BeautifulSoup\n",
        "    import requests\n",
        "    from PIL import Image\n",
        "    from io import BytesIO\n",
        "\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    images = soup.find_all('img')\n",
        "\n",
        "    for img in images:\n",
        "        src = img.get('src')\n",
        "        if src and src.startswith('http'):\n",
        "            try:\n",
        "                # Download image\n",
        "                response = requests.get(src)\n",
        "                img_data = Image.open(BytesIO(response.content))\n",
        "\n",
        "                # Optimize image\n",
        "                optimized_data = BytesIO()\n",
        "                img_data.save(optimized_data, format=img_data.format, optimize=True, quality=85)\n",
        "\n",
        "                # Convert to base64\n",
        "                import base64\n",
        "                base64_img = base64.b64encode(optimized_data.getvalue()).decode()\n",
        "                img['src'] = f\"data:image/{img_data.format.lower()};base64,{base64_img}\"\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error optimizing image {src}: {str(e)}\")\n",
        "\n",
        "    return str(soup)\n",
        "\n",
        "def minify_code(code: str, code_type: str) -> str:\n",
        "    \"\"\"Minify HTML, CSS, or JavaScript code\"\"\"\n",
        "    try:\n",
        "        if code_type == 'html':\n",
        "            from htmlmin import minify\n",
        "            return minify(code)\n",
        "        elif code_type == 'css':\n",
        "            from rcssmin import cssmin\n",
        "            return cssmin(code)\n",
        "        elif code_type == 'js':\n",
        "            from jsmin import jsmin\n",
        "            return jsmin(code)\n",
        "        return code\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error minifying {code_type} code: {str(e)}\")\n",
        "        return code\n",
        "\n",
        "# Add performance monitoring\n",
        "class PerformanceMonitor:\n",
        "    def __init__(self):\n",
        "        self.metrics = {}\n",
        "\n",
        "    def start_operation(self, operation_name: str):\n",
        "        self.metrics[operation_name] = {\n",
        "            'start_time': time.time()\n",
        "        }\n",
        "\n",
        "    def end_operation(self, operation_name: str):\n",
        "        if operation_name in self.metrics:\n",
        "            self.metrics[operation_name]['end_time'] = time.time()\n",
        "            self.metrics[operation_name]['duration'] = (\n",
        "                self.metrics[operation_name]['end_time'] -\n",
        "                self.metrics[operation_name]['start_time']\n",
        "            )\n",
        "\n",
        "    def get_metrics(self) -> Dict:\n",
        "        return {\n",
        "            name: data['duration']\n",
        "            for name, data in self.metrics.items()\n",
        "            if 'duration' in data\n",
        "        }\n",
        "\n",
        "# Add error handling middleware\n",
        "def error_handler(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        try:\n",
        "            return func(*args, **kwargs)\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
        "            st.error(f\"An error occurred: {str(e)}\")\n",
        "            return None\n",
        "    return wrapper\n",
        "\n",
        "# Add caching\n",
        "@st.cache_data(ttl=3600)\n",
        "def cache_website_build(user_prompt: str) -> Dict:\n",
        "    \"\"\"Cache website build results for 1 hour\"\"\"\n",
        "    builder = WebsiteBuilder()\n",
        "    return builder.build_website(user_prompt)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Initialize performance monitoring\n",
        "        performance_monitor = PerformanceMonitor()\n",
        "        performance_monitor.start_operation(\"main_execution\")\n",
        "\n",
        "        # Run the main application\n",
        "        main()\n",
        "\n",
        "        # End performance monitoring\n",
        "        performance_monitor.end_operation(\"main_execution\")\n",
        "\n",
        "        # Log performance metrics\n",
        "        metrics = performance_monitor.get_metrics()\n",
        "        logging.info(f\"Performance metrics: {json.dumps(metrics, indent=2)}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Application error: {str(e)}\")\n",
        "        st.error(\"An unexpected error occurred. Please try again later.\")"
      ],
      "metadata": {
        "id": "NTz4j9FVV6m3",
        "outputId": "2ea8161a-1141-4b38-c4e4-a4683ddd262e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-10-25 06:37:50.431 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
            "2024-10-25 06:37:50.435 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.438 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.444 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
            "2024-10-25 06:37:50.445 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.448 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.449 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.451 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.452 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.454 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.533 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-10-25 06:37:50.535 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.539 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.541 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.543 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.545 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.547 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.548 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.549 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.550 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.551 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.552 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.553 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.554 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.556 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.557 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.558 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.559 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.560 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.561 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.562 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.563 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.565 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.566 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-10-25 06:37:50.567 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uGJ9ybqHeuWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "import time\n",
        "from datetime import datetime\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, Any, List\n",
        "from zipfile import ZipFile\n",
        "import google.generativeai as genai\n",
        "from io import BytesIO\n",
        "import wikipedia\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "class Config:\n",
        "    GOOGLE_API_KEY = \"AIzaSyA5HtRnzGruiia-aKtMMLnBjJ0ovTh11nE\"  # Replace with your API key\n",
        "\n",
        "    COLORS = {\n",
        "        'primary': '#FF6B3D',\n",
        "        'secondary': '#FF8F6B',\n",
        "        'background': '#FFFFFF',\n",
        "        'text': '#1A1A1A',\n",
        "        'accent': '#FFE4DC'\n",
        "    }\n",
        "\n",
        "class WikipediaAPIWrapper:\n",
        "    @staticmethod\n",
        "    def fetch_wikipedia_summary(query):\n",
        "        wikipedia.set_lang(\"en\")\n",
        "        try:\n",
        "            summary = wikipedia.summary(query, sentences=2)\n",
        "            return summary\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error fetching Wikipedia summary: {e}\")\n",
        "            return None\n",
        "\n",
        "class BaseAgent(ABC):\n",
        "    def __init__(self, model: Any, temperature: float = 0.7):\n",
        "        self.model = model\n",
        "        self.temperature = temperature\n",
        "        self.logger = logging.getLogger(self.__class__.__name__)\n",
        "\n",
        "    def generate_response(self, prompt: str) -> str:\n",
        "        try:\n",
        "            response = self.model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "    @abstractmethod\n",
        "    def process(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "class LabelCreatorAgent(BaseAgent):\n",
        "    def process(self, user_prompt: str) -> Dict:\n",
        "        self.logger.info(\"Creating labels from user prompt\")\n",
        "        prompt = f\"\"\"\n",
        "        Analyze and create detailed labels for website requirements:\n",
        "        {user_prompt}\n",
        "\n",
        "        Generate a comprehensive JSON structure with:\n",
        "        1. Page Structure:\n",
        "           - Layout components\n",
        "           - Navigation elements\n",
        "           - Content sections\n",
        "        2. Design Requirements:\n",
        "           - Color scheme\n",
        "           - Typography\n",
        "           - Spacing and layout rules\n",
        "        3. Functionality:\n",
        "           - Interactive elements\n",
        "           - Forms and inputs\n",
        "           - Dynamic features\n",
        "        4. Content Requirements:\n",
        "           - Text sections\n",
        "           - Media elements\n",
        "           - Data requirements\n",
        "        5. Technical Specifications:\n",
        "           - Required libraries\n",
        "           - API integrations\n",
        "           - Performance requirements\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.generate_response(prompt)\n",
        "            return json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing JSON response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class TaskDistributorAgent(BaseAgent):\n",
        "    def process(self, labels: Dict) -> List[Dict]:\n",
        "        self.logger.info(\"Distributing tasks based on labels\")\n",
        "        prompt = f\"\"\"\n",
        "        Create a detailed task distribution plan for:\n",
        "        {json.dumps(labels, indent=2)}\n",
        "\n",
        "        Generate tasks for:\n",
        "        1. Frontend Development:\n",
        "           - Component creation\n",
        "           - Styling implementation\n",
        "           - Responsive design\n",
        "        2. Backend Integration:\n",
        "           - API endpoints\n",
        "           - Data processing\n",
        "           - Security features\n",
        "        3. Content Generation:\n",
        "           - Text content\n",
        "           - Media assets\n",
        "           - SEO elements\n",
        "        4. Testing Requirements:\n",
        "           - Unit tests\n",
        "           - Integration tests\n",
        "           - Performance testing\n",
        "\n",
        "        Return as JSON array with task details, dependencies, and priorities.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            response = self.generate_response(prompt)\n",
        "            return json.loads(response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing JSON response: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class CodingAgent(BaseAgent):\n",
        "    def process(self, task: Dict) -> Dict:\n",
        "        self.logger.info(f\"Generating code for task: {task.get('name', 'Unknown')}\")\n",
        "        prompt = f\"\"\"\n",
        "        Generate production-ready code for:\n",
        "        {json.dumps(task, indent=2)}\n",
        "\n",
        "        Include:\n",
        "        1. Complete component code\n",
        "        2. Styling (CSS/SCSS)\n",
        "        3. JavaScript functionality\n",
        "        4. Error handling\n",
        "        5. Documentation\n",
        "        6. Performance optimizations\n",
        "\n",
        "        Follow best practices for:\n",
        "        - Clean code\n",
        "        - Accessibility\n",
        "        - SEO\n",
        "        - Performance\n",
        "        \"\"\"\n",
        "        try:\n",
        "            code_response = self.generate_response(prompt)\n",
        "            return {\n",
        "                \"task\": task,\n",
        "                \"code\": code_response,\n",
        "                \"metadata\": {\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"version\": \"1.0\"\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error generating code: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class DesignAgent(BaseAgent):\n",
        "    def process(self, labels: Dict) -> Dict:\n",
        "        self.logger.info(\"Generating design system\")\n",
        "        prompt = f\"\"\"\n",
        "        Create a comprehensive design system based on:\n",
        "        {json.dumps(labels, indent=2)}\n",
        "\n",
        "        Include:\n",
        "        1. Color Palette:\n",
        "           - Primary colors\n",
        "           - Secondary colors\n",
        "           - Accent colors\n",
        "           - Semantic colors\n",
        "        2. Typography:\n",
        "           - Font families\n",
        "           - Font sizes\n",
        "           - Line heights\n",
        "           - Font weights\n",
        "        3. Spacing System:\n",
        "           - Grid system\n",
        "           - Margins\n",
        "           - Paddings\n",
        "        4. Component Styles:\n",
        "           - Buttons\n",
        "           - Forms\n",
        "           - Cards\n",
        "           - Navigation\n",
        "        5. Animation Guidelines:\n",
        "           - Transitions\n",
        "           - Hover states\n",
        "           - Loading states\n",
        "        \"\"\"\n",
        "        try:\n",
        "            design_response = self.generate_response(prompt)\n",
        "            return json.loads(design_response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing design system JSON: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class UpgradingAgent(BaseAgent):\n",
        "    def process(self, component: Dict) -> Dict:\n",
        "        self.logger.info(f\"Upgrading component: {component.get('task', {}).get('name', 'Unknown')}\")\n",
        "        prompt = f\"\"\"\n",
        "        Optimize and upgrade the following component:\n",
        "        {json.dumps(component, indent=2)}\n",
        "\n",
        "        Focus on:\n",
        "        1. Performance Optimization:\n",
        "           - Code splitting\n",
        "           - Lazy loading\n",
        "           - Resource optimization\n",
        "        2. Security Improvements:\n",
        "           - Input validation\n",
        "           - XSS prevention\n",
        "           - CSRF protection\n",
        "        3. Accessibility Enhancements:\n",
        "           - ARIA labels\n",
        "           - Keyboard navigation\n",
        "           - Screen reader support\n",
        "        4. SEO Optimization:\n",
        "           - Meta tags\n",
        "           - Semantic HTML\n",
        "           - Schema markup\n",
        "        \"\"\"\n",
        "        try:\n",
        "            upgraded_code = self.generate_response(prompt)\n",
        "            return {\n",
        "                \"task\": component[\"task\"],\n",
        "                \"original_code\": component[\"code\"],\n",
        "                \"upgraded_code\": upgraded_code,\n",
        "                \"upgrade_metadata\": {\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    \"version\": \"1.1\"\n",
        "                }\n",
        "            }\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error upgrading component: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class VerificationAgent(BaseAgent):\n",
        "    def process(self, website_data: Dict) -> Dict:\n",
        "        self.logger.info(\"Verifying website components and integration\")\n",
        "        prompt = f\"\"\"\n",
        "        Perform comprehensive verification of:\n",
        "        {json.dumps(website_data, indent=2)}\n",
        "\n",
        "        Check for:\n",
        "        1. Code Quality:\n",
        "           - Syntax validation\n",
        "           - Best practices\n",
        "           - Code standards\n",
        "        2. Integration:\n",
        "           - Component compatibility\n",
        "           - API integration\n",
        "           - State management\n",
        "        3. Performance:\n",
        "           - Load time optimization\n",
        "           - Resource usage\n",
        "           - Memory leaks\n",
        "        4. Security:\n",
        "           - Vulnerability scanning\n",
        "           - Input validation\n",
        "           - Authentication checks\n",
        "        5. Accessibility:\n",
        "           - WCAG compliance\n",
        "           - Screen reader compatibility\n",
        "           - Keyboard navigation\n",
        "        \"\"\"\n",
        "        try:\n",
        "            verification_response = self.generate_response(prompt)\n",
        "            return json.loads(verification_response)\n",
        "        except json.JSONDecodeError as e:\n",
        "            self.logger.error(f\"Error parsing verification results: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "class WikiContentGenerator:\n",
        "    def __init__(self, wikipedia_api_wrapper):\n",
        "        self.wiki = wikipedia_api_wrapper\n",
        "\n",
        "    def generate_content(self, topic: str) -> Dict:\n",
        "        try:\n",
        "            search_results = wikipedia.search(topic)\n",
        "            content = []\n",
        "            for result in search_results[:3]:\n",
        "                try:\n",
        "                    page = wikipedia.page(result)\n",
        "                    content.append({\n",
        "                        \"title\": page.title,\n",
        "                        \"summary\": page.summary,\n",
        "                        \"url\": page.url\n",
        "                    })\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error fetching wiki page {result}: {str(e)}\")\n",
        "                    continue\n",
        "            return {\"status\": \"success\", \"content\": content}\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error in wiki content generation: {str(e)}\")\n",
        "            return {\"status\": \"error\", \"message\": str(e)}\n",
        "\n",
        "class WebsiteBuilder:\n",
        "    def __init__(self, api_key):\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.model = genai.GenerativeModel('gemini-pro')\n",
        "        self.agents = {\n",
        "            \"label_creator\": LabelCreatorAgent(self.model),\n",
        "            \"task_distributor\": TaskDistributorAgent(self.model),\n",
        "            \"coding\": CodingAgent(self.model),\n",
        "            \"upgrading\": UpgradingAgent(self.model),\n",
        "            \"design\": DesignAgent(self.model),\n",
        "            \"verification\": VerificationAgent(self.model)\n",
        "        }\n",
        "        self.wiki_generator = WikiContentGenerator(WikipediaAPIWrapper())\n",
        "        self.logger = logging.getLogger(\"WebsiteBuilder\")\n",
        "\n",
        "    def build_website(self, user_prompt: str) -> Dict:\n",
        "        try:\n",
        "            # 1. Create labels\n",
        "            self.logger.info(\"Step 1: Creating labels\")\n",
        "            labels = self.agents[\"label_creator\"].process(user_prompt)\n",
        "\n",
        "            # 2. Generate content from Wikipedia if needed\n",
        "            if \"content_requirements\" in labels:\n",
        "                self.logger.info(\"Generating content from Wikipedia\")\n",
        "                for topic in labels[\"content_requirements\"]:\n",
        "                    wiki_content = self.wiki_generator.generate_content(topic)\n",
        "                    labels[\"wiki_content\"] = wiki_content\n",
        "\n",
        "            # 3. Create design system\n",
        "            self.logger.info(\"Step 2: Creating design system\")\n",
        "            design_system = self.agents[\"design\"].process(labels)\n",
        "\n",
        "            # 4. Distribute tasks\n",
        "            self.logger.info(\"Step 3: Distributing tasks\")\n",
        "            tasks = self.agents[\"task_distributor\"].process(labels)\n",
        "\n",
        "            # 5. Generate components\n",
        "            self.logger.info(\"Step 4: Generating components\")\n",
        "            components = []\n",
        "            for task in tasks:\n",
        "                component = self.agents[\"coding\"].process(task)\n",
        "                components.append(component)\n",
        "\n",
        "            # 6. Upgrade components\n",
        "            self.logger.info(\"Step 5: Upgrading components\")\n",
        "            upgraded_components = []\n",
        "            for component in components:\n",
        "                upgraded = self.agents[\"upgrading\"].process(component)\n",
        "                upgraded_components.append(upgraded)\n",
        "\n",
        "            # 7. Verify website\n",
        "            self.logger.info(\"Step 6: Verifying website\")\n",
        "            verification_results = self.agents[\"verification\"].process({\n",
        "                \"components\": upgraded_components,\n",
        "                \"design_system\": design_system,\n",
        "                \"labels\": labels\n",
        "            })\n",
        "\n",
        "            # 8. Save results\n",
        "            output = {\n",
        "                \"status\": \"success\",\n",
        "                \"labels\": labels,\n",
        "                \"design_system\": design_system,\n",
        "                \"components\": upgraded_components,\n",
        "                \"verification\": verification_results\n",
        "            }\n",
        "\n",
        "            # Save to files\n",
        "            os.makedirs(\"website_output\", exist_ok=True)\n",
        "\n",
        "            # Save individual components\n",
        "            for idx, component in enumerate(upgraded_components):\n",
        "                with open(f\"website_output/component_{idx + 1}.html\", \"w\") as f:\n",
        "                    f.write(component[\"upgraded_code\"])\n",
        "\n",
        "            # Save complete output\n",
        "            with open(\"website_output/build_result.json\", \"w\") as f:\n",
        "                json.dump(output, f, indent=2)\n",
        "\n",
        "            # Create ZIP file\n",
        "            with ZipFile(\"website_output/website.zip\", \"w\") as zipf:\n",
        "                for idx, component in enumerate(upgraded_components):\n",
        "                    zipf.writestr(f\"components/component_{idx + 1}.html\", component[\"upgraded_code\"])\n",
        "                zipf.writestr(\"design_system.json\", json.dumps(design_system, indent=2))\n",
        "                zipf.writestr(\"build_result.json\", json.dumps(output, indent=2))\n",
        "\n",
        "            return output\n",
        "\n",
        "        except Exception as e:\n",
        "            self.logger.error(f\"Error building website: {str(e)}\")\n",
        "            return {\n",
        "                \"status\": \"error\",\n",
        "                \"message\": str(e)\n",
        "            }\n",
        "\n",
        "def main():\n",
        "    # Example usage\n",
        "    api_key = \"AIzaSyA5HtRnzGruiia-aKtMMLnBjJ0ovTh11nE\"  # Replace with your actual API key\n",
        "\n",
        "    # Initialize the builder\n",
        "    builder = WebsiteBuilder(api_key)\n",
        "\n",
        "    # Example prompt\n",
        "    user_prompt = \"\"\"\n",
        "    Create a modern portfolio website with:\n",
        "    - A hero section with my name and profession\n",
        "    - About me section\n",
        "    - Projects showcase\n",
        "    - Skills and expertise\n",
        "    - Contact form\n",
        "    Use a minimal design with dark mode support.\n",
        "    \"\"\"\n",
        "\n",
        "    # Build the website\n",
        "    print(\"Starting website build...\")\n",
        "    result = builder.build_website(user_prompt)\n",
        "\n",
        "    # Check result\n",
        "    if result[\"status\"] == \"success\":\n",
        "        print(\"\\nWebsite built successfully!\")\n",
        "        print(\"\\nOutputs saved to 'website_output' directory:\")\n",
        "        print(\"- Individual components as HTML files\")\n",
        "        print(\"- Complete build result as JSON\")\n",
        "        print(\"- Zip file containing all components\")\n",
        "\n",
        "        # Print some statistics\n",
        "        print(f\"\\nComponents generated: {len(result['components'])}\")\n",
        "        print(f\"Verification status: {result['verification'].get('status', 'N/A')}\")\n",
        "    else:\n",
        "        print(f\"\\nError building website: {result['message']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "rJgI4dmmeuTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Yv7LGxIeuDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QC5GEtfteuAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ggb-A_uet8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XzDqNd2Bet6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yE_If7kset3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HgFHEW5ket0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EVZhbrYgetu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "seVRPxInetsO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zj-SuEMtetoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX2mtEoNetmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9RTTaLheti8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sXvjXw5Tetgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8lfOI6pReteS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VduCHATHetZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJLpvHMwetVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0Tw1_7BetS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove streamlit and test the above code with print statement and take user prompt give complete code dont leave anything for me\n",
        "\n",
        "# Remove streamlit and other unnecessary imports\n",
        "import wikipedia  # Importing wikipedia after installation\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from htmlmin import minify\n",
        "from rcssmin import cssmin\n",
        "from jsmin import jsmin\n",
        "\n",
        "\n",
        "def is_woodall(x):\n",
        "  if (x % 2 == 0):\n",
        "    return False\n",
        "  if (x == 1):\n",
        "    return True\n",
        "  x = x + 1\n",
        "  p = 0\n",
        "  while (x % 2 == 0):\n",
        "    x = x / 2\n",
        "    p = p + 1\n",
        "    if (p == x):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  try:\n",
        "    num = int(input(\"Enter a number to check if it's a Woodall number: \"))\n",
        "    if is_woodall(num):\n",
        "      print(f\"{num} is a Woodall number.\")\n",
        "    else:\n",
        "      print(f\"{num} is not a Woodall number.\")\n",
        "  except ValueError:\n",
        "    print(\"Invalid input. Please enter a valid integer.\")\n"
      ],
      "metadata": {
        "id": "pMTMfwWKdpUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5TIc-zy9deiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\n"
      ],
      "metadata": {
        "id": "UQHrnBI4V6lK",
        "outputId": "6959e820-586d-4aa0-aff5-17e7cc242574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.196.203.220:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove the streamlit in the code make it work with print and take user responce i want to test it is working or not give complete code please\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import time\n",
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import Dict, Any, List\n",
        "import json\n",
        "import logging\n",
        "import wikipedia  # Importing wikipedia after installation\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import base64\n",
        "from htmlmin import minify\n",
        "from rcssmin import cssmin\n",
        "from jsmin import jsmin\n",
        "\n",
        "\n",
        "def generate_response(prompt):\n",
        "    \"\"\"\n",
        "    Generates a response using the PaLM 2 API based on the given prompt.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = genai.generate_text(\n",
        "            model=\"models/chat-bison-001\",\n",
        "            prompt=prompt,\n",
        "            temperature=0.7,\n",
        "            max_output_tokens=256\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to handle user input and display the generated response.\n",
        "    \"\"\"\n",
        "    user_prompt = input(\"Enter your prompt: \")\n",
        "\n",
        "    if user_prompt:\n",
        "        response = generate_response(user_prompt)\n",
        "\n",
        "        if response:\n",
        "            print(\"Generated response:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "htExOu_IV6gl",
        "outputId": "44bb44ff-8cb1-401c-c2c2-720257e69ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: build a basic website for my burger shop\n",
            "Error generating response: module 'google.generativeai' has no attribute 'generate_text'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v9QaJcQHV6ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmwySq_EV6aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFqstKN6V6YU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSUuNx__V6T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xCwx-lOuV6SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUUAQS9u4biH"
      },
      "source": [
        "## What's next\n",
        "\n",
        "To learn more about working with the Gemini API, see the [Python tutorial](https://ai.google.dev/tutorials/python_quickstart).\n",
        "\n",
        "If you're new to generative AI models, you might want to look at the\n",
        "[concepts guide](https://ai.google.dev/docs/concepts) and the\n",
        "[Gemini API overview](https://ai.google.dev/docs/gemini_api_overview)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quickstart_colab.ipynb",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}